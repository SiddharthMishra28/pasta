DO $$
DECLARE
    r RECORD;
BEGIN
    FOR r IN
        SELECT tablename
        FROM pg_tables
        WHERE schemaname = 'source_schema'
    LOOP
        EXECUTE format(
            'CREATE TABLE target_schema.%I (LIKE source_schema.%I INCLUDING ALL);',
            r.tablename,
            r.tablename
        );

        EXECUTE format(
            'INSERT INTO target_schema.%I SELECT * FROM source_schema.%I;',
            r.tablename,
            r.tablename
        );
    END LOOP;
END $$;


---------------------------------------------------------


-- =====================================================
-- POSTGRESQL PRODUCTION MIGRATION: FlowExecution Primary Key Change
-- This script removes ALL flow execution and pipeline execution data
-- and recreates tables with BIGINT primary keys
-- =====================================================

-- IMPORTANT: BACKUP YOUR DATABASE BEFORE RUNNING THIS SCRIPT!
-- This will PERMANENTLY DELETE all flow execution and pipeline execution data

-- Step 1: Delete all pipeline executions first (child records)
DELETE FROM pipeline_executions;
-- Verification: Should show 0 records
SELECT COUNT(*) as pipeline_executions_count FROM pipeline_executions;

-- Step 2: Delete all flow executions (parent records)  
DELETE FROM flow_executions;
-- Verification: Should show 0 records
SELECT COUNT(*) as flow_executions_count FROM flow_executions;

-- Step 3: Drop existing tables (in correct order due to foreign keys)
DROP TABLE IF EXISTS pipeline_executions CASCADE;
DROP TABLE IF EXISTS flow_executions CASCADE;

-- Step 4: Recreate flow_executions table with BIGSERIAL primary key
CREATE TABLE flow_executions (
    id BIGSERIAL PRIMARY KEY,
    flow_id BIGINT NOT NULL,
    start_time TIMESTAMP(6),
    end_time TIMESTAMP(6),
    runtime_variables JSONB,
    status VARCHAR(255) CHECK (status IN ('PENDING','RUNNING','PASSED','FAILED','CANCELLED','SCHEDULED','IN_PROGRESS')),
    created_at TIMESTAMP(6) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    is_replay BOOLEAN DEFAULT FALSE,
    original_flow_execution_id BIGINT,
    flow_group_name VARCHAR(255),
    flow_group_id BIGINT,
    iteration INTEGER,
    revolutions INTEGER
);

-- Step 5: Recreate pipeline_executions table with BIGINT foreign key
CREATE TABLE pipeline_executions (
    id BIGSERIAL PRIMARY KEY,
    flow_id BIGINT NOT NULL,
    flow_execution_id BIGINT NOT NULL,
    flow_step_id BIGINT NOT NULL,
    pipeline_id BIGINT,
    pipeline_url VARCHAR(255),
    job_id BIGINT,
    job_url VARCHAR(255),
    start_time TIMESTAMP(6),
    end_time TIMESTAMP(6),
    configured_test_data JSONB,
    runtime_test_data JSONB,
    status VARCHAR(255) CHECK (status IN ('PENDING','RUNNING','PASSED','FAILED','CANCELLED','SCHEDULED','IN_PROGRESS')),
    created_at TIMESTAMP(6) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    is_replay BOOLEAN NOT NULL DEFAULT FALSE,
    resume_time TIMESTAMP(6),
    
    -- Foreign key constraint
    CONSTRAINT fk_pipeline_flow_execution 
    FOREIGN KEY (flow_execution_id) REFERENCES flow_executions(id) ON DELETE CASCADE
);

-- Step 6: Reset sequences to start from 1
-- PostgreSQL automatically creates sequences for BIGSERIAL columns
ALTER SEQUENCE flow_executions_id_seq RESTART WITH 1;
ALTER SEQUENCE pipeline_executions_id_seq RESTART WITH 1;

-- Step 7: Create indexes for performance (recommended for PostgreSQL)
CREATE INDEX idx_flow_executions_flow_id ON flow_executions(flow_id);
CREATE INDEX idx_flow_executions_status ON flow_executions(status);
CREATE INDEX idx_flow_executions_created_at ON flow_executions(created_at);
CREATE INDEX idx_pipeline_executions_flow_execution_id ON pipeline_executions(flow_execution_id);
CREATE INDEX idx_pipeline_executions_flow_step_id ON pipeline_executions(flow_step_id);
CREATE INDEX idx_pipeline_executions_status ON pipeline_executions(status);

-- =====================================================
-- VERIFICATION QUERIES
-- Run these after migration to confirm success
-- =====================================================

-- Check table structures
\d flow_executions;
\d pipeline_executions;

-- Verify record counts (should be 0)
SELECT COUNT(*) as flow_executions_count FROM flow_executions;
SELECT COUNT(*) as pipeline_executions_count FROM pipeline_executions;

-- Verify primary keys are BIGSERIAL (BIGINT with auto-increment)
SELECT 
    schemaname, 
    tablename, 
    column_name, 
    data_type, 
    is_nullable, 
    column_default 
FROM information_schema.columns 
WHERE table_name IN ('flow_executions', 'pipeline_executions') 
AND column_name = 'id'
ORDER BY table_name;

-- Verify sequences
SELECT sequence_name, start_value, increment_by FROM information_schema.sequences 
WHERE sequence_name IN ('flow_executions_id_seq', 'pipeline_executions_id_seq');

-- Test auto-increment (optional - insert test record and verify)
-- INSERT INTO flow_executions (flow_id, status) VALUES (1, 'RUNNING');
-- SELECT * FROM flow_executions;
-- DELETE FROM flow_executions WHERE id = 1; -- Clean up test record

COMMIT;
